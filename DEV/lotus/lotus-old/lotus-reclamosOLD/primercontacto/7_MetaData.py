# Databricks notebook source
import pandas as pd
import numpy as np
path_escritura = '/mnt/lotus-reclamos-storage/primercontacto'
# Eliminar archivo de propiedades existente
dbutils.fs.rm("/dbfs"+path_escritura+"/metadata_lotus_db.txt", True)
# Enable Arrow-based columnar data transfers
spark.conf.set("spark.sql.execution.arrow.enabled", "true")
# Describe de la tabla
meta = spark.sql("""DESCRIBE PROCESS.ZDP_LOTUS_RECLAMOS_PRIMERCONTACTO_TABLAINTERMEDIA""")
# Conversion a Pandas Dataframe
pmeta = meta.select("*").toPandas()
pmeta.to_csv("/dbfs"+path_escritura+"/metadata_lotus_db.txt", index=False, columns=['col_name', 'data_type'], sep='|')